{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_dict():\n",
    "    # This encoding is done based on per-capita-income-rating\n",
    "\n",
    "    state_dict = { 33: \"Andaman and Nicobar Islands\",17 : \"Andhra Pradesh\",18 : \"Arunachal Pradesh\",28 : \"Assam\",\n",
    "    32 : \"Bihar\",4 : \"Chandigarh\",25 : \"Chhattisgarh\",3 : \"Delhi\",1 : \"Goa\",10 : \"Gujarat\",5 : \"Haryana\",\n",
    "    14 : \"Himachal Pradesh\",23 : \"Jammu and Kashmir\",30 : \"Jharkhand\",6 : \"Karnataka\",8 : \"Kerala\",26 : \"Madhya Pradesh\",\n",
    "    12 : \"Maharashtra\",29 : \"Manipur\",27 : \"Meghalaya\",15 : \"Mizoram\",19 : \"Nagaland\",22 : \"Odisha\",7 : \"Puducherry\",\n",
    "    16 : \"Punjab\",21 : \"Rajasthan\",2 : \"Sikkim\",13 : \"Tamil Nadu\",9 : \"Telangana\",20 : \"Tripura\",31 : \"Uttar Pradesh\",\n",
    "    11 : \"Uttarakhand\",24 : \"West Bengal\" }\n",
    "    \n",
    "    state_dict = dict([(value, int(key)) for key, value in state_dict.items()])\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def get_cities_dict():\n",
    "    # Ranking goes top to Bottom\n",
    "\n",
    "    cities_list_ranked = [\"Bengaluru\",\"Pune\",\"Ahmedabad\",\"Chennai\",\"Surat\",\"Navi Mumbai\",\"Coimbatore\",\"Vadodara\",\"Indore\",\n",
    "          \"Greater Mumbai\",\"Thane\",\"Kalyan Dombivali\",\"New Delhi\",\"Noida\",\"Ludhiana\",\"Visakhapatnam\",\"Pimpri Chinchwad\",\n",
    "    \"Solapur\",\"Raipur\",\"Bhopal\",\"Rajkot\",\"Jodhpur\",\"Madurai\",\"Jaipur\",\"Hyderabad\",\"Nagpur\",\"Lucknow\",\"Varanasi\",\n",
    "    \"Kanpur\",\"Chandigarh\",\"Ghaziabad\",\"Gwalior\",\"Prayagraj\",\"Patna\",\"Aurangabad\",\"Agra\",\"Meerut\",\"Hubli Dharwad\",\n",
    "    \"Nashik\",\"Vasai Virar\",\"Faridabad\",\"Vijayawada\",\"Ranchi\",\"Jabalpur\",\"Kota\",\"Amritsar\",\"Guwahati\",\"Barielly\",\n",
    "    \"Dhanbad\",\"Srinagar\" ]\n",
    "\n",
    "    # The cities which are not present will be added at last, and one feature would be if they are present or not\n",
    "\n",
    "    bool_city = list(np.ones((len(cities_list_ranked)),dtype = np.int64))\n",
    "    \n",
    "    for i in full_data.city.values:\n",
    "        i = i.split(\"[\")[0]\n",
    "        if i not in cities_list_ranked:\n",
    "            bool_city.append(0)\n",
    "            cities_list_ranked.append(i)\n",
    "\n",
    "    # Create a dictionary for Mapping\n",
    "\n",
    "    cities_dict = {}\n",
    "    for i,city in enumerate(cities_list_ranked):\n",
    "        cities_dict[city] = i\n",
    "\n",
    "    return cities_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profess_dict(method):\n",
    "    \n",
    "    if method == 1 :\n",
    "        # Based of Avg Salary\n",
    "        \n",
    "        profess_mean = []\n",
    "\n",
    "        for i in full_data.profession.unique():\n",
    "            inc = full_data[full_data.profession == i][\"income\"].mean()\n",
    "            profess_mean.append([i,inc])\n",
    "\n",
    "        profess_mean = np.array(profess_mean)[np.array(profess_mean)[:,1].argsort()]\n",
    "\n",
    "        profess_dict = {}\n",
    "\n",
    "        for i,prof in enumerate(profess_mean):\n",
    "            profess_dict[prof[0]] = i\n",
    "        \n",
    "        return profess_dict\n",
    "    \n",
    "    elif method == 2 :\n",
    "        # Based on risk flag\n",
    "\n",
    "        profess_mean = []\n",
    "\n",
    "        for i in full_data.profession.unique():\n",
    "            inc = full_data[full_data.profession == i][\"risk_flag\"].sum()\n",
    "            profess_mean.append([i,inc])\n",
    "\n",
    "        profess_mean = np.array(profess_mean)[np.array(profess_mean)[:,1].argsort()]\n",
    "\n",
    "        profess_dict = {}\n",
    "\n",
    "        for i,prof in enumerate(profess_mean):\n",
    "            profess_dict[prof[0]] = i\n",
    "\n",
    "        return profess_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"Training Data.csv\")\n",
    "test_data = pd.read_csv(\"Test Data.csv\")\n",
    "full_data = pd.concat([train_data,test_data],axis=0)\n",
    "\n",
    "# test_data = train_data[:50000].reset_index(drop=True)\n",
    "# train_data = train_data[50000:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process profession --- >\n",
    "\n",
    "profess = train_data.profession.unique()\n",
    "new_profess = []\n",
    "\n",
    "for i in profess:\n",
    "    i = i.replace(\"_\", \" \")\n",
    "    new_profess.append(i)\n",
    "    \n",
    "for i, j in zip(profess,new_profess):\n",
    "    train_data.profession = train_data.profession.replace(i,j)\n",
    "    \n",
    "profess = test_data.profession.unique()\n",
    "new_profess = []\n",
    "\n",
    "for i in profess:\n",
    "    i = i.replace(\"_\", \" \")\n",
    "    new_profess.append(i)\n",
    "    \n",
    "for i, j in zip(profess,new_profess):\n",
    "    test_data.profession = test_data.profession.replace(i,j)\n",
    "    \n",
    "for j,i in enumerate(train_data.city.values):\n",
    "    train_data.city.values[j] = i.split(\"[\")[0]\n",
    "    \n",
    "for j,i in enumerate(test_data.city.values):\n",
    "    test_data.city.values[j] = i.split(\"[\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process state  --- >\n",
    "\n",
    "state = train_data.state.unique()\n",
    "new_state = []\n",
    "\n",
    "for i in state:\n",
    "    i = i.replace(\"_\", \" \")\n",
    "    new_state.append(i)\n",
    "    \n",
    "for i, j in zip(state,new_state):\n",
    "    train_data.state = train_data.state.replace(i,j)\n",
    "    \n",
    "state = test_data.state.unique()\n",
    "new_state = []\n",
    "\n",
    "for i in state:\n",
    "    i = i.replace(\"_\", \" \")\n",
    "    new_state.append(i)\n",
    "    \n",
    "for i, j in zip(state,new_state):\n",
    "    test_data.state = test_data.state.replace(i,j)\n",
    "\n",
    "train_data.state = train_data.state.replace(\"Uttar Pradesh[5]\",\"Uttar Pradesh\")\n",
    "test_data.state = test_data.state.replace(\"Uttar Pradesh[5]\",\"Uttar Pradesh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how train dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert datatype of selected fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profession_sort = 2 # 1 or 2\n",
    "\n",
    "train_data.state = train_data.state.map(get_state_dict()).astype(np.int64)\n",
    "train_data.city = train_data.city.map(get_cities_dict())\n",
    "train_data.profession = train_data.profession.map(get_profess_dict(profession_sort))\n",
    "\n",
    "test_data.state = test_data.state.map(get_state_dict())\n",
    "test_data.city = test_data.city.map(get_cities_dict())\n",
    "test_data.profession = test_data.profession.map(get_profess_dict(profession_sort)) \n",
    "\n",
    "\n",
    "train_data[\"married\"]=pd.factorize(train_data.married)[0]\n",
    "train_data[\"house_ownership\"]=pd.factorize(train_data.house_ownership)[0]\n",
    "train_data[\"car_ownership\"]=pd.factorize(train_data.car_ownership)[0]\n",
    "\n",
    "test_data[\"married\"]=pd.factorize(test_data.married)[0]\n",
    "test_data[\"house_ownership\"]=pd.factorize(test_data.house_ownership)[0]\n",
    "test_data[\"car_ownership\"]=pd.factorize(test_data.car_ownership)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop the dependent variable from the train/test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train_data.drop(\"risk_flag\",axis=1).drop(\"Id\",axis=1)\n",
    "ytrain=train_data[\"risk_flag\"]\n",
    "test_data=test_data.drop(\"id\",axis=1)\n",
    "# ytest=test_data[\"risk_flag\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop unnamed field from train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xtrain_Unnamed  = xtrain.pop(\"Unnamed: 0\")\n",
    "# xtest_Unnamed  = xtest.pop(\"Unnamed: 0\")\n",
    "xtrain = np.array(xtrain)\n",
    "# xtest  = np.array(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,xtrain,ytrain,xval,yval):\n",
    "    model.fit(xtrain,ytrain,eval_set=(xval, yval),verbose_eval= True,use_best_model=True)\n",
    "    y_pred = model.predict(xtrain)\n",
    "    auc = roc_auc_score(ytrain, y_pred)\n",
    "    print('Train ROC AUC: %f' % auc)\n",
    "    y_pred = model.predict(xval)\n",
    "    auc = roc_auc_score(yval, y_pred)\n",
    "    print('Val ROC AUC: %f' % auc)\n",
    "    return model,y_pred,auc\n",
    "\n",
    "def get_pred(model,xtest):\n",
    "    return model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "\n",
    "y_test_oof = []\n",
    "y_pred_oof = []\n",
    "\n",
    "all_preds = {}\n",
    "\n",
    "for itr,(train_index,test_index) in enumerate(skf(folds, random_state= 0, shuffle=True).split(xtrain,ytrain)):\n",
    "    print(f\"Train size {len(train_index)} | Val size {len(test_index)}\")\n",
    "    print()\n",
    "    X_train, X_test = xtrain[train_index], xtrain[test_index]\n",
    "    y_train, y_test = ytrain[train_index], ytrain[test_index]\n",
    "    \n",
    "    model = CatBoostRegressor(iterations=3000, depth=10, learning_rate=0.1 ,l2_leaf_reg=3, loss_function='RMSE',verbose=False)\n",
    "    model,y_pred,auc = train(model,X_train,y_train,X_test,y_test)\n",
    "    \n",
    "    print(f\"Doing Prediction for auc {auc}\")\n",
    "    all_preds[str(auc) + str(itr)] = get_pred(model,test_data)\n",
    "    \n",
    "    y_test_oof.extend(y_test)\n",
    "    y_pred_oof.extend(y_pred)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "oof = roc_auc_score(y_test_oof, y_pred_oof)\n",
    "print('OOF ROC AUC: %f' % oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "With Classifier :\n",
    "OOF ROC AUC: 0.843004 : (iterations=15, depth=3, learning_rate=0.5, loss_function='CrossEntropy',verbose=False)\n",
    "OOF ROC AUC: 0.874740 : (iterations=14, depth=3, learning_rate=0.5, loss_function='Logloss',verbose=False)\n",
    "\n",
    "With Regressor :\n",
    "\n",
    "OOF ROC AUC: 0.890554 : (iterations=1000, depth=5, learning_rate=1.0, loss_function='RMSE',verbose=False)\n",
    "OOF ROC AUC: 0.930738 : (iterations=3000, depth=10, learning_rate=0.1 ,l2_leaf_reg=3, loss_function='RMSE',verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE, MultiRMSE, MAE, Quantile, LogLinQuantile, Poisson, MAPE, Lq or custom objective object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred(DTClassifier,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = np.array(train_data.columns)[1:-1]\n",
    "impt = DTClassifier.feature_importances_\n",
    "\n",
    "df = pd.DataFrame([cols,impt]).T.rename({0:\"Feature\",1:\"Importance\"},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_data(sub):\n",
    "    sub = pd.DataFrame(base)[0]\n",
    "    sub = sub.rank() / sub.rank().max()\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {'learning_rate': [0.03, 0.1,1.0],\n",
    "#     'depth': [4, 6, 10],\n",
    "#     'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
    "\n",
    "# model = CatBoostRegressor(iterations=2000,loss_function='RMSE',verbose=False)\n",
    "# grid_search_result = model.grid_search(grid, \n",
    "#                                    X=xtrain, \n",
    "#                                    y=ytrain, \n",
    "#                                    stratified = True,\n",
    "#                                    cv = 5,\n",
    "#                                    plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>risk_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  risk_flag\n",
       "0          1          0\n",
       "1          2          0\n",
       "2          3          1\n",
       "3          4          0\n",
       "4          5          0\n",
       "...      ...        ...\n",
       "27995  27996          0\n",
       "27996  27997          1\n",
       "27997  27998          0\n",
       "27998  27999          0\n",
       "27999  28000          0\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv(\"Sample Prediction Dataset.csv\")\n",
    "base = np.zeros(len(test_data))\n",
    "for val in all_preds.values():\n",
    "    base += np.array(val)\n",
    "\n",
    "base/= folds\n",
    "sample_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub['risk_flag'] = (rank_data(base) >= 0.5)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub.to_csv(\"ranked.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>risk_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>27996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>27997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>27998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>27999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>28000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  risk_flag\n",
       "0          1          0\n",
       "1          2          1\n",
       "2          3          0\n",
       "3          4          1\n",
       "4          5          0\n",
       "...      ...        ...\n",
       "27995  27996          0\n",
       "27996  27997          0\n",
       "27997  27998          0\n",
       "27998  27999          1\n",
       "27999  28000          1\n",
       "\n",
       "[28000 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.418935\n",
       "1        0.507519\n",
       "2        0.118999\n",
       "3        0.744356\n",
       "4        0.149039\n",
       "           ...   \n",
       "27995    0.334959\n",
       "27996    0.448225\n",
       "27997    0.427615\n",
       "27998    0.796721\n",
       "27999    0.832351\n",
       "Name: 0, Length: 28000, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_data(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.007795\n",
       "1        0.013241\n",
       "2       -0.001260\n",
       "3        0.164691\n",
       "4       -0.000410\n",
       "           ...   \n",
       "27995    0.004356\n",
       "27996    0.009124\n",
       "27997    0.008128\n",
       "27998    0.237952\n",
       "27999    0.329370\n",
       "Name: 0, Length: 28000, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
